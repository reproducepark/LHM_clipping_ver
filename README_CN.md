# <span><img src="./assets/LHM_logo_parsing.png" height="35" style="vertical-align: top;"> - å®˜æ–¹ PyTorch å®ç°</span>

[![é¡¹ç›®ä¸»é¡µ](https://img.shields.io/badge/ğŸŒ-é¡¹ç›®ä¸»é¡µ-blueviolet)](https://lingtengqiu.github.io/LHM/)
[![arXivè®ºæ–‡](https://img.shields.io/badge/ğŸ“œ-arXiv:2503-10625)](https://arxiv.org/pdf/2503.10625)
[![HuggingFace](https://img.shields.io/badge/ğŸ¤—-HuggingFace_Space-blue)](https://huggingface.co/spaces/DyrusQZ/LHM)
[![Apacheåè®®](https://img.shields.io/badge/ğŸ“ƒ-Apache--2.0-929292)](https://www.apache.org/licenses/LICENSE-2.0)

<p align="center">
  <img src="./assets/LHM_teaser.png" heihgt="100%">
</p>

## ğŸ“¢ æœ€æ–°åŠ¨æ€
**[March 19, 2025]** æœ¬åœ°éƒ¨ç½² Gradio<br>
**[2025å¹´3æœˆ19æ—¥]** HuggingFace Demoï¼šæ›´å¿«æ›´ç¨³å®š <br>
**[2025å¹´3æœˆ15æ—¥]** æ¨ç†æ—¶é—´ä¼˜åŒ–ï¼šæé€Ÿ30% <br>
**[2025å¹´3æœˆ13æ—¥]** é¦–æ¬¡ç‰ˆæœ¬å‘å¸ƒåŒ…å«ï¼š  
âœ… æ¨ç†ä»£ç åº“  
âœ… é¢„è®­ç»ƒ LHM-0.5B æ¨¡å‹  
âœ… é¢„è®­ç»ƒ LHM-1B æ¨¡å‹  
âœ… å®æ—¶æ¸²æŸ“ç®¡çº¿  
âœ… Huggingface åœ¨çº¿æ¼”ç¤º  

### å¾…åŠæ¸…å•
- [x] æ ¸å¿ƒæ¨ç†ç®¡çº¿ (v0.1) ğŸ”¥ğŸ”¥ğŸ”¥
- [x] HuggingFace æ¼”ç¤ºé›†æˆ ğŸ¤—ğŸ¤—ğŸ¤—
- [ ] ModelScope éƒ¨ç½²
- [ ] åŠ¨ä½œå¤„ç†è„šæœ¬ 
- [ ] è®­ç»ƒä»£ç å‘å¸ƒ

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒé…ç½®
å…‹éš†ä»“åº“
```bash
git clone git@github.com:aigc3d/LHM.git
cd LHM
```

é€šè¿‡è„šæœ¬å®‰è£…ä¾èµ–
```
# cuda 11.8
sh ./install_cu118.sh

# cuda 12.1
sh ./install_cu121.sh
```
ç¯å¢ƒå·²åœ¨ python3.10ã€CUDA 11.8 å’Œ CUDA 12.1 ä¸‹æµ‹è¯•é€šè¿‡ã€‚

ä¹Ÿå¯æŒ‰æ­¥éª¤æ‰‹åŠ¨å®‰è£…ä¾èµ–ï¼Œè¯¦è§[INSTALL.md](INSTALL.md)

### æ¨¡å‹å‚æ•° 

<span style="color:red">å¦‚æœä½ æ²¡ä¸‹è½½æ¨¡å‹ï¼Œæ¨¡å‹å°†ä¼šè‡ªåŠ¨ä¸‹è½½</span>

æ¨¡å‹	è®­ç»ƒæ•°æ®	BH-Tå±‚æ•°	ä¸‹è½½é“¾æ¥	æ¨ç†æ—¶é—´
LHM-0.5B	5Kåˆæˆæ•°æ®	5	OSS	2.01 s
LHM-0.5B	300Kè§†é¢‘+5Kåˆæˆæ•°æ®	5	OSS	2.01 s
LHM-0.7B	300Kè§†é¢‘+5Kåˆæˆæ•°æ®	10	OSS	4.13 s
LHM-1.0B	300Kè§†é¢‘+5Kåˆæˆæ•°æ®	15	OSS	6.57 s

| æ¨¡å‹ | è®­ç»ƒæ•°æ® | Transformer å±‚æ•° | ä¸‹è½½é“¾æ¥ | æ¨ç†æ—¶é—´ |
| :--- | :--- | :--- | :--- | :--- |
| LHM-0.5B | 5Kåˆæˆæ•°æ®| 5 | OSS | 2.01 s |
| LHM-0.5B | 300Kè§†é¢‘+5Kåˆæˆæ•°æ® | 5 | [OSS](https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-0.5B.tar) | 2.01 s |
| LHM-0.7B | 300Kè§†é¢‘+5Kåˆæˆæ•°æ® | 10 | OSS | 4.13 s  |
| LHM-1.0B | 300Kè§†é¢‘+5Kåˆæˆæ•°æ® | 15 | [OSS](https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-1B.tar) | 6.57 s |

```bash
# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹æƒé‡
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-0.5B.tar
tar -xvf LHM-0.5B.tar 
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-1B.tar
tar -xvf LHM-1B.tar
```

### ä¸‹è½½å…ˆéªŒæ¨¡å‹æƒé‡
```bash
# ä¸‹è½½å…ˆéªŒæ¨¡å‹æƒé‡
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM_prior_model.tar
tar -xvf LHM_prior_model.tar 
```

### åŠ¨ä½œæ•°æ®å‡†å¤‡
æˆ‘ä»¬æä¾›äº†æµ‹è¯•åŠ¨ä½œç¤ºä¾‹ï¼Œå¤„ç†è„šæœ¬å°†å°½å¿«æ›´æ–° :)

```bash
# ä¸‹è½½å…ˆéªŒæ¨¡å‹æƒé‡
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/motion_video.tar
tar -xvf ./motion_video.tar 
```

ä¸‹è½½å®Œæˆåé¡¹ç›®ç›®å½•ç»“æ„å¦‚ä¸‹ï¼š
```bash
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ inference
â”‚   â”œâ”€â”€ accelerate-train-1gpu.yaml
â”‚   â”œâ”€â”€ accelerate-train-deepspeed.yaml
â”‚   â”œâ”€â”€ accelerate-train.yaml
â”‚   â””â”€â”€ infer-gradio.yaml
â”œâ”€â”€ engine
â”‚   â”œâ”€â”€ BiRefNet
â”‚   â”œâ”€â”€ pose_estimation
â”‚   â”œâ”€â”€ SegmentAPI
â”œâ”€â”€ example_data
â”‚   â””â”€â”€ test_data
â”œâ”€â”€ exps
â”‚   â”œâ”€â”€ releases
â”œâ”€â”€ LHM
â”‚   â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ losses
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ outputs
â”‚   â”œâ”€â”€ runners
â”‚   â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ launch.py
â”œâ”€â”€ pretrained_models
â”‚   â”œâ”€â”€ dense_sample_points
â”‚   â”œâ”€â”€ gagatracker
â”‚   â”œâ”€â”€ human_model_files
â”‚   â”œâ”€â”€ sam2
â”‚   â”œâ”€â”€ sapiens
â”‚   â”œâ”€â”€ voxel_grid
â”‚   â”œâ”€â”€ arcface_resnet18.pth
â”‚   â”œâ”€â”€ BiRefNet-general-epoch_244.pth
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ exp
â”‚   â”œâ”€â”€ convert_hf.py
â”‚   â””â”€â”€ upload_hub.py
â”œâ”€â”€ tools
â”‚   â”œâ”€â”€ metrics
â”œâ”€â”€ train_data
â”‚   â”œâ”€â”€ example_imgs
â”‚   â”œâ”€â”€ motion_video
â”œâ”€â”€ inference.sh
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```



### ğŸ’» æœ¬åœ°éƒ¨ç½² 
```bash
python ./app.py
```

### ğŸƒ æ¨ç†æµç¨‹
```bash
# MODEL_NAME={LHM-500M, LHM-1B}
# bash ./inference.sh ./configs/inference/human-lrm-500M.yaml LHM-500M ./train_data/example_imgs/ ./train_data/motion_video/mimo1/smplx_params
# bash ./inference.sh ./configs/inference/human-lrm-1B.yaml LHM-1B ./train_data/example_imgs/ ./train_data/motion_video/mimo1/smplx_params

bash inference.sh ${CONFIG} ${MODEL_NAME} ${IMAGE_PATH_OR_FOLDER}  ${MOTION_SEQ}
```

## è®¡ç®—æŒ‡æ ‡
æˆ‘ä»¬æä¾›äº†ç®€å•çš„æŒ‡æ ‡è®¡ç®—è„šæœ¬ï¼š
```bash
# download pretrain model into ./pretrained_models/
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/arcface_resnet18.pth
# Face Similarity
python ./tools/metrics/compute_facesimilarity.py -f1 ${gt_folder} -f2 ${results_folder}
# PSNR 
python ./tools/metrics/compute_psnr.py -f1 ${gt_folder} -f2 ${results_folder}
# SSIM LPIPS 
python ./tools/metrics/compute_ssim_lpips.py -f1 ${gt_folder} -f2 ${results_folder} 
```

## è‡´è°¢

æœ¬å·¥ä½œåŸºäºä»¥ä¸‹ä¼˜ç§€ç ”ç©¶æˆæœå’Œå¼€æºé¡¹ç›®æ„å»ºï¼š

- [OpenLRM](https://github.com/3DTopia/OpenLRM)
- [ExAvatar](https://github.com/mks0601/ExAvatar_RELEASE)
- [DreamGaussian](https://github.com/dreamgaussian/dreamgaussian)

æ„Ÿè°¢è¿™äº›æ°å‡ºå·¥ä½œå¯¹3Dç”Ÿæˆå’Œæ•°å­—äººé¢†åŸŸçš„é‡è¦è´¡çŒ®ã€‚

## å¼•ç”¨ 
```
@inproceedings{qiu2025LHM,
  title={LHM: Large Animatable Human Reconstruction Model for Single Image to 3D in Seconds},
  author={Lingteng Qiu and Xiaodong Gu and Peihao Li  and Qi Zuo
     and Weichao Shen and Junfei Zhang and Kejie Qiu and Weihao Yuan
     and Guanying Chen and Zilong Dong and Liefeng Bo 
    },
  booktitle={arXiv preprint arXiv:2503.10625},
  year={2025}
}
```
